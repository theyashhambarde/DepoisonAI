{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DepoisonAI: Text Data Poisoning Demo (IMDB Movie Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and Imports",
    "import pandas as pd",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "import sys",
    "from sklearn.model_selection import train_test_split",
    "from sklearn.feature_extraction.text import TfidfVectorizer",
    "from sklearn.linear_model import LogisticRegression",
    "from sklearn.metrics import accuracy_score",
    "from datasets import load_dataset",
    "\n",
    "# Add src to path to import our custom modules",
    "sys.path.append('../src')",
    "from utils.helpers import set_seed, LOGGER",
    "from poison_detection.text_detectors import detect_text_outliers_tfidf",
    "from depoisoning_methods.text_cleaners import filter_text_samples",
    "from evaluation.performance import plot_confusion_matrix, compare_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading",
    "set_seed(42)",
    "LOGGER.info(\"Loading IMDB dataset...\")",
    "\n",
    "# Load a smaller subset for faster demo",
    "dataset = load_dataset('imdb', split='train[:5000]')",
    "df = pd.DataFrame(dataset)",
    "\n",
    "X = df['text']",
    "y = df['label']",
    "\n",
    "LOGGER.info(f\"Dataset loaded. Shape: {X.shape}\")",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Simulate Data Poisoning (Label Flipping)",
    "POISON_FRACTION = 0.20",
    "LOGGER.info(f\"Simulating a label flipping attack. Poisoning {POISON_FRACTION*100}% of the data.\")",
    "\n",
    "y_poisoned = y.copy()",
    "num_poisoned_samples = int(len(y) * POISON_FRACTION)",
    "poison_indices = np.random.choice(y.index, size=num_poisoned_samples, replace=False)",
    "\n",
    "y_poisoned.loc[poison_indices] = 1 - y_poisoned.loc[poison_indices]",
    "LOGGER.info(f\"Flipped {len(poison_indices)} labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Baseline Model: Train on POISONED Data",
    "LOGGER.info(\"Training baseline model on the POISONED dataset...\")",
    "\n",
    "X_train, X_test, y_train_poisoned, y_test = train_test_split(X, y_poisoned, test_size=0.2, random_state=42, stratify=y_poisoned)",
    "_, _, y_train_clean, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_poisoned)",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')",
    "X_train_tfidf = vectorizer.fit_transform(X_train)",
    "X_test_tfidf = vectorizer.transform(X_test)",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)",
    "model.fit(X_train_tfidf, y_train_poisoned)",
    "\n",
    "y_pred_poisoned = model.predict(X_test_tfidf)",
    "accuracy_poisoned = accuracy_score(y_test, y_pred_poisoned)",
    "LOGGER.info(f\"Accuracy of model trained on POISONED data: {accuracy_poisoned:.4f}\")",
    "plot_confusion_matrix(y_test, y_pred_poisoned, class_names=['Negative', 'Positive'], title='Confusion Matrix (Poisoned Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Detect Poisoning",
    "LOGGER.info(\"Running poison detection on the training data...\")",
    "\n",
    "suspicious_indices = detect_text_outliers_tfidf(X_train.to_numpy(), contamination=POISON_FRACTION)",
    "\n",
    "# Evaluate detection performance",
    "actual_poison_in_train = np.where(y_train_poisoned.reset_index(drop=True) != y_train_clean.reset_index(drop=True))[0]",
    "detected_correctly = np.intersect1d(suspicious_indices, actual_poison_in_train)",
    "print(f\"Poison Detection Recall: {len(detected_correctly) / len(actual_poison_in_train):.2%} ({len(detected_correctly)} of {len(actual_poison_in_train)} found)")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Depoison the Dataset",
    "LOGGER.info(\"Applying depoisoning by filtering...\")",
    "\n",
    "X_train_df = pd.DataFrame({'text': X_train})",
    "y_train_series = pd.Series(y_train_poisoned, name='label')",
    "\n",
    "X_train_cleaned, y_train_cleaned = filter_text_samples(X_train_df, y_train_series, suspicious_indices)",
    "LOGGER.info(f\"Cleaned dataset size: {len(X_train_cleaned)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Final Model: Train on CLEANED Data",
    "LOGGER.info(\"Training final model on the CLEANED dataset...\")",
    "\n",
    "X_train_cleaned_tfidf = vectorizer.fit_transform(X_train_cleaned['text'])",
    "\n",
    "model_cleaned = LogisticRegression(max_iter=1000, random_state=42)",
    "model_cleaned.fit(X_train_cleaned_tfidf, y_train_cleaned)",
    "\n",
    "y_pred_cleaned = model_cleaned.predict(X_test_tfidf)",
    "accuracy_cleaned = accuracy_score(y_test, y_pred_cleaned)",
    "LOGGER.info(f\"Accuracy of model trained on CLEANED data: {accuracy_cleaned:.4f}\")",
    "plot_confusion_matrix(y_test, y_pred_cleaned, class_names=['Negative', 'Positive'], title='Confusion Matrix (Cleaned Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Final Evaluation and Comparison",
    "LOGGER.info(\"Final Performance Comparison")",
    "eval_before = {'accuracy': accuracy_poisoned}",
    "eval_after = {'accuracy': accuracy_cleaned}",
    "compare_evaluations(eval_before, eval_after, metric='accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
